{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF5ybQxDZZj2"
      },
      "source": [
        "# **CompaniesMarketCap.com**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXZ_lc_7ZQQn",
        "outputId": "e51ea62e-0f60-4787-9a72-ef795f0c927b"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "from csv import writer\n",
        "\n",
        "# Definizione del dataframe\n",
        "df = pd.DataFrame(columns=['Name', 'Symbol','MarketCap',  'Price', 'Country'])\n",
        "\n",
        "i = 1 #variabile da incrementare per scorrere le pagine dell'url del sito\n",
        "\n",
        "#scorriamo le prime 10 pagine del sito\n",
        "while i < 11:\n",
        "\n",
        "  j = str(i)    #la variabile va convertita in stringa per essere passata nell'url\n",
        "  link = 'https://companiesmarketcap.com/page/'+j+'/'\n",
        "  print(link)\n",
        "\n",
        "  data = requests.get(link).text\n",
        "\n",
        "  soup = BeautifulSoup(data, 'html.parser')\n",
        "\n",
        "  # Troviamo le tabelle e le classi\n",
        "  print('Classes of each table:')\n",
        "  for table in soup.find_all('table'):\n",
        "      print(table.get('class'))\n",
        "\n",
        "  # Troviamo tutte le righe\n",
        "  for row in table.tbody.find_all('tr'):    #scorre le righe\n",
        "      # Troviamo le colonne\n",
        "      columns = row.find_all('td')    #scorre i dati della tabella\n",
        "    \n",
        "      if(columns != []):\n",
        "          name = row.find('div', class_=\"company-name\").text.replace('\\n', '')\n",
        "          symbol = row.find('div', class_='company-code').text.replace('\\n', '')\n",
        "          mcap = columns[2].text.strip()\n",
        "          price = columns[3].text.strip()\n",
        "          country = columns[6].text[3:].strip()\n",
        "\n",
        "          df = df.append({'Name': name, 'Symbol' : symbol, 'MarketCap': mcap, 'Price': price, 'Country': country}, ignore_index=True)\n",
        "\n",
        "  del link\n",
        "  i = i+1\n",
        "\n",
        "df.head(None)   #stampa la tabella [senza (None) stampa solo le prime 5 righe]\n",
        "\n",
        "df.to_excel(\"companiesCMP.xls\")    #probabilmente formato migliore per salvarlo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoeL2SA2ZXlJ"
      },
      "source": [
        "# **Forbes.com**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCRe7lBAZhXk",
        "outputId": "16926d2c-51ab-4c28-dcd1-f9983c38fc1f"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "from csv import writer\n",
        "\n",
        "# Definizione del dataframe\n",
        "df = pd.DataFrame(columns=['Name', 'Country', 'Sales',  'Profit', 'Assets', 'Market Value'])\n",
        "\n",
        "link = 'https://www.forbes.com/lists/global2000/'\n",
        "print(link)\n",
        "\n",
        "data = requests.get(link).text\n",
        "\n",
        "soup = BeautifulSoup(data, 'html.parser')\n",
        "\n",
        "# Troviamo le tabelle e le classi\n",
        "print('Classes of each table:')\n",
        "for table in soup.find_all(\"a\", {\"class\": \"table-row\"}):    #A quanto pare questo for è fondamentale perchè definisce l'elemento 'table'\n",
        "    print(table.get('class'))\n",
        "\n",
        "# Creiamo una lista\n",
        "tables = soup.find_all(\"a\", {\"class\": \"table-row\"})\n",
        "\n",
        "i = 0\n",
        "# Collecting Ddata\n",
        "for row in tables:    #scorre le righe\n",
        "    # Find all data for each column\n",
        "    columns = row.find_all('div')    #scorre i dati della tabella\n",
        "    \n",
        "    if(columns != []):\n",
        "        name = columns[1].text.strip()\n",
        "        country = columns[2].text.strip()\n",
        "        sales = columns[3].text.strip()\n",
        "        profit = columns[4].text.strip()\n",
        "        assets = columns[5].text.strip()\n",
        "        mvalue = columns[6].text.strip()\n",
        "\n",
        "        df = df.append({'Name': name, 'Country' : country, 'Sales': sales, 'Profit': profit, 'Assets': assets, 'Market Value': mvalue}, ignore_index=True)\n",
        "    \n",
        "    i = i+1\n",
        "    if(i>999): #Ci bastano 1000 elementi\n",
        "      break\n",
        "\n",
        "df.head\n",
        "df.to_excel(\"companiesForbes.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOwYi1HLZhnu"
      },
      "source": [
        "# **Wikipedia.org**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awb9zjWHZjf0",
        "outputId": "5f20255a-8cfd-408c-985d-4a87b9b14449"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "from csv import writer\n",
        "\n",
        "df = pd.DataFrame(columns=['Name', 'Industry','Sector',  'Headquarters', 'Founded', 'Notes'])\n",
        "\n",
        "#1035 elementi totali con questi 3 link\n",
        "links = ['https://en.wikipedia.org/wiki/List_of_companies_of_Italy', 'https://en.wikipedia.org/wiki/List_of_companies_of_Germany', 'https://en.wikipedia.org/wiki/List_of_companies_of_Sweden']\n",
        "\n",
        "for link in links:\n",
        "  data = requests.get(link).text\n",
        "  print(link)\n",
        "\n",
        "  soup = BeautifulSoup(data, 'html.parser')\n",
        "\n",
        "  print('Classes of each table:')\n",
        "  for table in soup.find_all(\"table\", {\"class\": \"wikitable\"}):\n",
        "      print(table.get('class'))\n",
        "\n",
        "  tables = soup.find_all('table')\n",
        "\n",
        "  for row in tables[1].tbody.find_all('tr'):    #scorre le righe della seconda tabella\n",
        "      \n",
        "      columns = row.find_all('td')    #scorre i dati della tabella\n",
        "    \n",
        "      if(columns != []):\n",
        "          name = columns[0].text.strip()\n",
        "          industry = columns[1].text.strip()\n",
        "          sector = columns[2].text.strip()\n",
        "          if(sector == \"-\"):\n",
        "            sector = \"\"\n",
        "          hq = columns[3].text.strip()\n",
        "          if(hq == \"?\"):\n",
        "            hq = \"\"\n",
        "          founded = columns[4].text.strip()\n",
        "          if(len(founded)>4):\n",
        "            founded = founded[:4]\n",
        "          if(founded == \"?\"):\n",
        "            founded = \"\"\n",
        "          notes = columns[5].text.strip()\n",
        "\n",
        "          df = df.append({'Name': name, 'Industry' : industry, 'Sector': sector, 'Headquarters': hq, 'Founded': founded, 'Notes': notes}, ignore_index=True)\n",
        "\n",
        "df.head\n",
        "df.to_excel(\"companiesWiki.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8hKckzPZj8H"
      },
      "source": [
        "# **Disfold.com**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS0dEOvOZn98",
        "outputId": "4b9cbd38-b56c-4f3d-ad4c-c261e6a5b085"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "from csv import writer\n",
        "\n",
        "# Defining of the dataframe\n",
        "df = pd.DataFrame(columns=['Name', 'MarketCap', 'Stock', 'Country', 'Sector', 'Industry'])\n",
        "\n",
        "i = 1 #variabile da incrementare per scorrere le pagine dell'url del sito\n",
        "\n",
        "#scorriamo le 20 pagine del sito \n",
        "while i < 21:\n",
        "  j = str(i)    #la variabile va convertita in stringa per essere passata nell'url\n",
        "  link = 'https://disfold.com/world/companies/?page='+j\n",
        "  print(link)\n",
        "  \n",
        "  data = requests.get(link).text\n",
        "\n",
        "  soup = BeautifulSoup(data, 'html.parser')\n",
        "\n",
        "  print('Classes of each table:')\n",
        "  for table in soup.find_all('table'):\n",
        "      print(table.get('class'))\n",
        "\n",
        "  tables = soup.find_all('table')\n",
        "  \n",
        "  for row in table.tbody.find_all('tr'):    #scorre le righe\n",
        "\n",
        "      columns = row.find_all('td')    #scorre i dati della tabella\n",
        "    \n",
        "      if(columns != []):\n",
        "          name = columns[1].text.strip()\n",
        "          #alcuni elementi hanno un figlio 'p' che indica una data, quindi nel caso ci fosse vogliamo escluderlo e prendere solo il primo elemento del <td>\n",
        "          if(columns[2].find('p')):\n",
        "            mcap = columns[2].contents[0].strip()\n",
        "          else:\n",
        "            mcap = columns[2].text.strip()\n",
        "          stock = columns[3].text.strip()\n",
        "          country = columns[4].text.strip()\n",
        "          sector = columns[5].text.strip()\n",
        "          industry = columns[6].text.strip()\n",
        "\n",
        "          df = df.append({'Name': name, 'MarketCap' : mcap, 'Stock': stock, 'Country': country, 'Sector': sector, 'Industry': industry}, ignore_index=True)\n",
        "\n",
        "  del link\n",
        "  i = i+1\n",
        "\n",
        "df.head(None)   #stampa la tabella [senza (None) stampa solo le prime 5 righe]\n",
        "\n",
        "df.to_excel(\"companiesDisfold.xls\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('venv_hw5_idd': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "f6d8a1e8e5ee541ab424cd0b76c3f1491b8a1f8e61473444831a3e206f9ac4ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
